{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnaxamin/off-target_inhibition_hppy/blob/master/dnn_class_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXtGQvGgtrid"
      },
      "source": [
        "Install and import necessary things."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fk11hqVzY054"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21ZagMTxYGzV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, Softmax\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt\n",
        "from pandas import read_csv, concat, DataFrame\n",
        "import numpy as np\n",
        "from math import floor, ceil, sqrt\n",
        "from statistics import mean\n",
        "from tensorflow.keras.metrics import FalseNegatives, FalsePositives, TrueNegatives, TruePositives, Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j40Zx1EPqcvk"
      },
      "outputs": [],
      "source": [
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcxPz3oet3rG"
      },
      "source": [
        "Function to balance imbalanced data by oversampling the minority class - the minority class is replicated the maximum number of times that allow the minority class to remain in the minority."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5_X4N7MYLPE"
      },
      "outputs": [],
      "source": [
        "# oversample minority class (inhibitors) in imbalanced data to give a more balanced dataset\n",
        "# input_x is a df, input_y is a numpy array\n",
        "def data_balancer(input_x, input_y):\n",
        "    num_inhibitors = sum(input_y)\n",
        "    num_non_inhibitors = len(input_y) - num_inhibitors\n",
        "    if num_non_inhibitors/num_inhibitors < 2:  # data sufficiently balanced\n",
        "        x_out = input_x\n",
        "        y_out = input_y\n",
        "    else:   # data imbalanced\n",
        "        # x = DataFrame(input_x)\n",
        "        y = input_y.to_frame()\n",
        "        data = concat([input_x, y], axis=1)\n",
        "        times_to_replicate = floor(num_non_inhibitors/num_inhibitors) - 1\n",
        "        inhibitors = data[data['classification'] == 1]\n",
        "        inhibitors_replicated = concat([inhibitors]*times_to_replicate, ignore_index=True)\n",
        "        data_balanced = concat([data, inhibitors_replicated], ignore_index=True)\n",
        "        x_out = data_balanced.drop(['classification'], axis=1)\n",
        "        y_out = data_balanced['classification']\n",
        "    return x_out, y_out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC5PcqBft57V"
      },
      "source": [
        "Function to make 1D data (e.g. a 1D numpy array) into a 2D array that is the smallest square-shape possible without losing information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlChkYWdYSuV"
      },
      "outputs": [],
      "source": [
        "def make_one_dim_array_square(one_d):\n",
        "    length = len(one_d)\n",
        "    dim = ceil(sqrt(length))\n",
        "    square = np.zeros(shape=(dim, dim))\n",
        "    for i in range(length):\n",
        "        row_idx = floor(i / dim)\n",
        "        col_idx = i % dim\n",
        "        square[row_idx, col_idx] = one_d[i]\n",
        "    return square"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18ro9RG5uOZG"
      },
      "source": [
        "Function that uses the above function to convert data in a dataframe (a sequence of rows containing data) into a collection of 2D arrays ('images') - each 'image' corresponding to a row of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBcdJFhRYWbr"
      },
      "outputs": [],
      "source": [
        "def data_df_to_images(df_input):\n",
        "    df_input_list = [df_input.loc[i] for i in df_input.index]\n",
        "    output_images = np.array([make_one_dim_array_square(series) for series in df_input_list])\n",
        "    return output_images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0sVJMWuukAo"
      },
      "source": [
        "Function to train (and utilise) a number of neural networks independently and return an output assembled from the output of all the neural networks. The number of neural networks is determined by num_nets.  \n",
        "\n",
        "If used to get training and validation statistics and histories - procedure='fitting' - the forest outputs a Series with the training and validation loss and accuracies, and a num_nets-long list of keras.callbacks.History objects.\n",
        "\n",
        "If used on test or prediction data - procedure='testing'/'predicting' - the forest outputs an array with the pooled predictions, and a num_nets-long list of keras.callbacks.History objects.\n",
        "\n",
        "Definition of y_train_forest depends on what the metrics used. If only accuracy is used, y_train_forest = data_input[1] is sufficient. If true and false positives and negatives are used, the alternative definition must be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNNRe-3EYcKc"
      },
      "outputs": [],
      "source": [
        "def neural_forest(num_nets, data_input, callback_forest, train_frac_forest=0.8, val_frac_forest=0.1,\n",
        "                   num_epochs=50, shuffle_bool=False):\n",
        "    assert len(data_input) == 4, 'Number of data inputs should be 4 - x_train, y_train, x_test and x_predict'\n",
        "    forest_train_val_stats = DataFrame()\n",
        "    forest_test_votes = DataFrame()\n",
        "    forest_predict_votes = DataFrame()\n",
        "    histories = []\n",
        "    x_train_forest = data_input[0]\n",
        "    y_train_forest = data_input[1]\n",
        "    for i in range(num_nets):\n",
        "        print(i + 1)\n",
        "        model = build_tuned_model()\n",
        "        history = model.fit(x_train_forest, y_train_forest, epochs=num_epochs,\n",
        "                            validation_split=(val_frac_forest / (train_frac_forest + val_frac_forest)),\n",
        "                            shuffle=shuffle_bool, callbacks=[callback_forest])\n",
        "        histories.append(history)\n",
        "\n",
        "        # get train-val stats\n",
        "        history_df = DataFrame(history.history)\n",
        "        train_val_stats = history_df.iloc[[-1]]\n",
        "        forest_train_val_stats = concat([forest_train_val_stats, train_val_stats])\n",
        "\n",
        "        prediction_model = tf.keras.Sequential([model, Softmax()])\n",
        "        # get test predictions\n",
        "        x_test_forest = data_input[2]\n",
        "        test_prediction_probabilities = prediction_model.predict(x_test_forest)\n",
        "        test_prediction = np.array(\n",
        "            [np.argmax(test_prediction_probabilities[i]) for i in range(test_prediction_probabilities.shape[0])])\n",
        "        forest_test_votes = concat([forest_test_votes, DataFrame([test_prediction])])\n",
        "\n",
        "        # get UKB predictions\n",
        "        x_predict_forest = data_input[3]\n",
        "        prediction_probabilities = prediction_model.predict(x_predict_forest)\n",
        "        prediction = np.array(\n",
        "            [np.argmax(prediction_probabilities[i]) for i in range(prediction_probabilities.shape[0])])\n",
        "        forest_predict_votes = concat([forest_predict_votes, DataFrame([prediction])])\n",
        "\n",
        "    forest_test_consensus = forest_test_votes.mean()\n",
        "    forest_test_consensus_out = np.round(np.array(forest_test_consensus))\n",
        "    forest_predict_consensus = forest_predict_votes.mean()\n",
        "    forest_predict_consensus_out = np.round(np.array(forest_predict_consensus))\n",
        "\n",
        "    return [histories, forest_train_val_stats, forest_test_consensus_out, forest_predict_consensus_out]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmRelwuJvmn2"
      },
      "source": [
        "Function to get performance metrics of a fitted model. Inputs true values and predictions from that model. Returns accuracy, sensitivity, specificity, balanced accuracy and the F1 score. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4BIr7QcYeUT"
      },
      "outputs": [],
      "source": [
        "def performance_metrics(y_true, y_pred):\n",
        "    accuracy = Accuracy()\n",
        "    accuracy.update_state(y_true, y_pred)\n",
        "    accuracy_val = accuracy.result().numpy()\n",
        "    fn = FalseNegatives()\n",
        "    fn.update_state(y_true, y_pred)\n",
        "    fn_val = fn.result().numpy()\n",
        "    fp = FalsePositives()\n",
        "    fp.update_state(y_true, y_pred)\n",
        "    fp_val = fp.result().numpy()\n",
        "    tn = TrueNegatives()\n",
        "    tn.update_state(y_true, y_pred)\n",
        "    tn_val = tn.result().numpy()\n",
        "    tp = TruePositives()\n",
        "    tp.update_state(y_true, y_pred)\n",
        "    tp_val = tp.result().numpy()\n",
        "    sensitivity = tp_val / (tp_val + fn_val)\n",
        "    specificity = tn_val / (tn_val + fp_val)\n",
        "    balanced_accuracy = mean([sensitivity, specificity])\n",
        "    precision = tp_val / (tp_val + fp_val)\n",
        "    f1 = 2 * (sensitivity * precision)/(sensitivity + precision)\n",
        "    return {'accuracy': accuracy_val, 'sensitivity': sensitivity, 'specificity': specificity, \n",
        "            'balanced_accuracy': balanced_accuracy, 'f1': f1}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWN46LMtYjJV"
      },
      "outputs": [],
      "source": [
        "train_frac = 0.60\n",
        "val_frac = 0.20\n",
        "test_frac = 0.20\n",
        "\n",
        "callback = EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "df = read_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/happyhour_inhibitor_name_class_fingerprints.csv')\n",
        "\n",
        "df_train = df.sample(frac=train_frac+val_frac, random_state=42)\n",
        "df_test = df.drop(df_train.index)\n",
        "\n",
        "x_train_df = df_train.drop(['molecule_chembl_id', 'classification'], axis=1)\n",
        "y_train = df_train['classification']\n",
        "x_train_df, y_train = data_balancer(x_train_df, y_train)\n",
        "\n",
        "x_train = data_df_to_images(x_train_df)\n",
        "y_train = np.array(y_train)\n",
        "x_test = data_df_to_images(df_test.drop(['molecule_chembl_id', 'classification'], axis=1))\n",
        "y_test = np.array(df_test['classification'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cmPQ1Ru4sD0"
      },
      "source": [
        "Build the tuned model, with the only metric being accuracy. Output from this model is named with dnn_tuned*x*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma-Xoo2CYZi9"
      },
      "outputs": [],
      "source": [
        "def build_tuned_model():\n",
        "    best_hps_df = read_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/hppy_dnn_best_hps_60_20_20_run4.csv')\n",
        "    model = tf.keras.Sequential([\n",
        "        Flatten(input_shape=(30, 30)),\n",
        "        Dense(160, activation='relu'),\n",
        "        Dropout(rate=0.25),\n",
        "        Dense(2)])\n",
        "    learning_rate = best_hps_df['lr'][0]\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7VsOyO2tHKF"
      },
      "outputs": [],
      "source": [
        "ukb_drugs_descriptor = read_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/drug_ukb_name_fingerprints.csv')\n",
        "ukb_drugs_fingerprints = ukb_drugs_descriptor.drop(['Name'], axis=1)\n",
        "ukb_drugs_notna = read_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/drug_ukb_cleaned.csv')\n",
        "\n",
        "ukb_drugs_images = data_df_to_images(ukb_drugs_fingerprints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HHEkaGdYmS9"
      },
      "outputs": [],
      "source": [
        "forest = neural_forest(100, [x_train, y_train, x_test, ukb_drugs_images],\n",
        "                       callback_forest=callback,\n",
        "                       train_frac_forest=train_frac,\n",
        "                       val_frac_forest=val_frac,\n",
        "                       num_epochs=500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzdSl_Ve7dFG"
      },
      "source": [
        "Unpack the neural_forest output. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxXQaGlh7UoN"
      },
      "outputs": [],
      "source": [
        "forest_histories = forest[0]\n",
        "forest_train_val = forest[1]\n",
        "forest_test = forest[2]\n",
        "forest_predict = forest[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHCweBRo8pkL"
      },
      "source": [
        "Save outputs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJnOfP8s8Jk_"
      },
      "outputs": [],
      "source": [
        "for i, history in enumerate(forest_histories):\n",
        "    history_df = DataFrame(history.history)\n",
        "    history_df.to_csv(f'/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/class_2/dnn_tuned3/run2/dnn_tuned3_run2_training_val_history_{i}.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2qFaPRNqa88"
      },
      "outputs": [],
      "source": [
        "forest_train_val.to_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/class_2/dnn_tuned3/run2/dnn_tuned3_run2_train_val_stats.csv', index=False)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8VYWqc2ifQ8"
      },
      "outputs": [],
      "source": [
        "stats_testing = performance_metrics(y_true=y_test, y_pred=forest_test)\n",
        "DataFrame([stats_testing]).to_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/class_2/dnn_tuned3/run2/dnn_tuned3_run2_test_stats.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhHeEVh6tb4B"
      },
      "outputs": [],
      "source": [
        "ukb_drugs_dnn_classed = concat([ukb_drugs_notna.drop(['Drug', 'Drug_curated', 'smiles'], axis=1),\n",
        "                              DataFrame(np.vstack(forest_predict), columns=['predicted_classification'])], axis=1)\n",
        "dnn_active_ukb_drugs = ukb_drugs_dnn_classed[ukb_drugs_dnn_classed['predicted_classification'] == 1]\n",
        "dnn_active_ukb_drugs.to_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/class_2/dnn_tuned3/run2/dnn_tuned3_run2_active_ukb_drugs.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tuned3_run3 - example of combining steps above into one cell"
      ],
      "metadata": {
        "id": "6t1HWDudVOJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest = neural_forest(100, [x_train, y_train, x_test, ukb_drugs_images],\n",
        "                       callback_forest=callback,\n",
        "                       train_frac_forest=train_frac,\n",
        "                       val_frac_forest=val_frac,\n",
        "                       num_epochs=500)\n",
        "forest_histories = forest[0]\n",
        "forest_train_val = forest[1]\n",
        "forest_test = forest[2]\n",
        "forest_predict = forest[3]\n",
        "\n",
        "for i, history in enumerate(forest_histories):\n",
        "    history_df = DataFrame(history.history)\n",
        "    history_df.to_csv(f'/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/class_2/dnn_tuned3/run3/dnn_tuned3_run3_training_val_history_{i}.csv', index=False)\n",
        "  \n",
        "forest_train_val.to_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/class_2/dnn_tuned3/run3/dnn_tuned3_run3_train_val_stats.csv', index=False) \n",
        "\n",
        "stats_testing = performance_metrics(y_true=y_test, y_pred=forest_test)\n",
        "DataFrame([stats_testing]).to_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/class_2/dnn_tuned3/run3/dnn_tuned3_run3_test_stats.csv', index=False)\n",
        "\n",
        "ukb_drugs_dnn_classed = concat([ukb_drugs_notna.drop(['Drug', 'Drug_curated', 'smiles'], axis=1),\n",
        "                              DataFrame(np.vstack(forest_predict), columns=['predicted_classification'])], axis=1)\n",
        "dnn_active_ukb_drugs = ukb_drugs_dnn_classed[ukb_drugs_dnn_classed['predicted_classification'] == 1]\n",
        "dnn_active_ukb_drugs.to_csv('/content/drive/MyDrive/partIII_sysbiol2021/happyhour_inhibition_ml/class_2/dnn_tuned3/run3/dnn_tuned3_run3_active_ukb_drugs.csv', index=False)"
      ],
      "metadata": {
        "id": "SlrvBVeYVBRx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "dnn_class_colab",
      "provenance": [],
      "mount_file_id": "1DXPAiXT7JmqvScV0S2AhYLOSRtorxHvu",
      "authorship_tag": "ABX9TyN6pQ3CHHTxF2921uZtrnWg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}